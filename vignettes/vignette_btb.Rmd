---
title: "Spatial smoothing with BTB R package"
author: "Julien PRAMIL"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Spatial smoothing with BTB R package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.height = 5,
  fig.width = 5,fig.align = 'center'
  
  
)
```


This document will show you :

* How to install 'btb' package
* How to do your first spatial smoothings :
  * densities
  * means
  * rates
  * quantiles smothings

Furthermore, it will introduce a way to map your results using 'mapsf' package and how to save your smoothed spatial data using 'sf'. 

# Install 'btb' package

`btb` is available on CRAN : 

```{r setup , eval = FALSE}
install.packages("btb")
```

But you can also download `btb` from github.com : 

```{r, eval = F}
install.packages("remotes")
remotes::install_github("InseeFrLab/btb")
```


# Let's do it

## Warning with personnal data 

Spatial smoothing generally reduces individual data disclosure. 
However, smoothed data can contain individual information.
Please remain cautious in any case. 

## Smoothing gas station prices

### The data

`btb` package provides several data tables. Lets's use `dfPrix_SP95_2016`.
For every gas station in metropolitan France, this table gives :

  * longitude / latitude coordinates (as numeric variables)
  * annual mean price for unleaded gasoline in € for (2016)

```{r seepoints , eval = T}
library(btb)
data(dfPrix_SP95_2016)
head(dfPrix_SP95_2016)
```

Let's visualize theses stations : 
  
  * First : use `sf` package to transform your data.frame as geometric points.
  * Then : plot it

```{r cartopoints}
library(sf)
sfPrix_SP95_2016 <- st_as_sf(dfPrix_SP95_2016,coords = c("x","y"), crs=2154)
plot(sfPrix_SP95_2016$geometry)
```

## Optional step : from points to aggregate grids

To figure out your spatial distribution before to smooth you data, it can be good to aggregate your points inside a grid (e.g : number of gas stations in 20 km pixels grid). 

`btb` provids the `btb_add_centroids` and the `btb_ptsToGrid` functions to make it easy : 

* First : associate each point with the centroid of its pixel (`btb_add_centroids`)
* Secondly : aggregate your data by centroids
* To finish : associate each centroid coordinates with its geometric polygon (`btb_ptsToGrid`)

```{r, addcentro}
# Step 1 
dfPrix_SP95_2016 <- btb_add_centroids(dfPrix_SP95_2016,iCellSize = 20000,names_coords = c("x","y"))
head(dfPrix_SP95_2016)
```


```{r checkgrid}
# Step 2
library(dplyr)
centro_values <- dfPrix_SP95_2016 %>% group_by(x_centro,y_centro) %>% summarise(pricemean=mean(SP95,rm.na=T))

# Step 3
grid_values <- btb_ptsToGrid(centro_values,sEPSG = 2154,iCellSize = 20000,names_centro = c("x_centro","y_centro"))
nrow(grid_values)
head(grid_values)

```

Once you have your polygons and your aggregated data, you can map it.
Here, we use the 'mapsf' package.

```{r seegrid}
library(mapsf)

mapsf::mf_map(x = grid_values,
       type = "choro",
       var="pricemean",
       breaks = "quantile",
       nbreaks = 5,
       lwd=1,
       leg_val_rnd = 1)
```

This map represents your aggregated (mean price) but not smoothed yet.
Despite its patchwork aspect, this map could be a good first step to better understand your data.

## First smoothing : the density of gas stations

On the example below, we smooth the density of gas stations using 5\~000 km pixels and a 100 km bandwidth. 
Note that we need to create a new dummy variable (equals to 1 for every station). 

```{r smooth_density}

pts_density <- dfPrix_SP95_2016[,c("x","y")]
# Create dummy
pts_density$stations_density <- 1L
head(pts_density)

# Smoothing
smooth_density <- btb_smooth(
  pts = pts_density,
  sEPSG = 2154,
  iBandwidth = 100000,
  iCellSize = 5000)

head(smooth_density)

# Map
mapsf::mf_map(x = smooth_density,
       type = "choro",
       var="stations_density",
       breaks = "quantile",
       nbreaks = 5,
       border = NA,
       leg_val_rnd = 1)
```

## Smoothing means : gas mean price

Smoothing a ratio works almost the same way.
First, you need to smooth both nominator and denominator.
Then, to calculate a properly smoothed ratio, you must calculate the ratio of theses 2 smoothed variables (smoothed nominator / smoothed denominator).
Note that the `btb_smooth` function smoothes all numeric variables in the input points table (parameter `pts`).


```{r smooth_mean_price}
# Prepare your data
pts_meanprice <- dfPrix_SP95_2016[,c("x","y","SP95")]
pts_meanprice$stations_density <- 1L
head(pts_meanprice)

# Smooth both prices and station density
smooth_density <- btb_smooth(
  pts = pts_meanprice,
  sEPSG = 2154,
  iBandwidth = 100000,
  iCellSize = 5000)

head(smooth_density)

# Calculate the smoothed mean (from smoothed nominator and denominator)
smooth_density <- smooth_density %>% mutate(meanprice=SP95/stations_density)
mapsf::mf_map(x = smooth_density,
       type = "choro",
       var="meanprice",
       breaks = "quantile",
       nbreaks = 5,
       border = NA,
       leg_val_rnd = 1)
```

```{r,include=F}
Cstack_info()
```

## Quantile smoothing : smooth the distribution of gas prices

Quantile smoothing is a different methodology. 
Its major benefits are : 
  * less sensitive to outliers
  * gives information on the distribution of your data

For more theorical information, please see (XXXXXXXX : formation séquence lissage théorique).



```{r quantile_smooth}

pts_quantiles <- dfPrix_SP95_2016[,c("x","y","SP95")]
head(pts_quantiles)

smooth_quantiles <- btb_smooth(pts = pts_quantiles,sEPSG = 2154,iBandwidth = 100000,iCellSize = 5000,vQuantiles = c(0.5,0.9))

head(smooth_quantiles)

# Median smoothing : 
mapsf::mf_map(x = smooth_quantiles,
       type = "choro",
       var="SP95_05",
       breaks = "quantile",
       nbreaks = 5,
       border = NA,
       leg_val_rnd = 1)

# Smooth the 9th decile :
mapsf::mf_map(x = smooth_quantiles,
       type = "choro",
       var="SP95_09",
       breaks = "quantile",
       nbreaks = 5,
       border = NA,
       leg_val_rnd = 1)

```


## The iNeighbor parameter

Here, we use fiscal data in La Réunion island.
Each point is the centroid of the grid used to publish aggregated data (1\ 000 meters pixels).

Let's smooth the proportion of poors among households. 

In the following example, note that the `btb_smooth` function accepts sf points in input (also the case with `btb_ptsToGrid`). 


```{r ratesmooth}
data("reunion")
head(reunion)

# Optional : transform as sf points
sfreunion <- sf::st_as_sf(reunion,coords= c("x","y"), crs = 3727)
plot(sfreunion$geometry)

# btb_smooth works with sf points
smooth_reunion <- btb_smooth(sfreunion,iCellSize = 500,iBandwidth = 5000)

# Calculate the ratio
smooth_reunion <- smooth_reunion %>% mutate(prop_poors = 100 * phouhold / houhold)

mapsf::mf_map(x = smooth_reunion,
       type = "choro",
       var="prop_poors",
       breaks = "quantile",
       nbreaks = 5,
       border = NA,
       leg_val_rnd = 1)
```

```{r neighboors}
smooth_reunion <- btb_smooth(sfreunion,iCellSize = 500,iBandwidth = 5000, iNeighbor = 0)
smooth_reunion <- smooth_reunion %>% mutate(prop_poors = 100 * phouhold / houhold)

mapsf::mf_map(x = smooth_reunion,
       type = "choro",
       var="prop_poors",
       breaks = "quantile",
       nbreaks = 5,
       border = NA,
       leg_val_rnd = 1)
```

```{r inpire}
smooth_reunion <- btb_smooth(sfreunion,iCellSize = 500,iBandwidth = 2000, iNeighbor = 0,inspire = T)
smooth_reunion <- smooth_reunion %>% mutate(prop_poors = 100 * phouhold / houhold)
head(smooth_reunion)

```

```{r export, eval=F}
sf::write_sf("MY/REPOSITORY/myfile.gpkg")
```

```{r, eval = F}
data(dfPrix_SP95_2016)
dfObservations <- dfPrix_SP95_2016
dfObservations$nbObs <- 1L
dfObservations$SP95 <- as.integer(100*dfObservations$SP95)

#### Affichage des donnes carroyes relles (nouvelle fonction KIM / 
# devra tre probablement la premire tape de la fonction kernelSmoothing) 

carroyage <- function(dfObservations,xOffset=0,yOffset=0, iCellSize=200L, var){
  
  dfSortie <- dfObservations
  dfSortie$col <- as.integer(floor((dfSortie$x - xOffset[1]) / iCellSize) - floor(min(dfSortie$x / iCellSize)) + 1)
  dfSortie$row <- as.integer(floor((dfSortie$y - yOffset[1]) / iCellSize) - floor(min(dfSortie$y / iCellSize)) + 1)
dfSortie <- dfSortie[order(dfSortie$row,dfSortie$col),] #tri par ligne puis col
  dfCentroids <- data.frame( x = as.integer(floor(dfSortie$x / iCellSize) * iCellSize + (iCellSize / 2)),
                             y = as.integer(floor(dfSortie$y / iCellSize) * iCellSize + (iCellSize / 2))
  )
  
  # Si on veut faire ajouter la colonne des carreaux, il faut fait cela
  # dfSortie <- cbind(dfSortie[, !names(dfSortie) %in% c("col","row")], 
  #               sf::st_geometry(dfToGrid(df = dfCentroids, sEPSG = "2154", iCellSize = iCellSize))
  # )
  
      # Sinon si on veut agreger par carreaux...
  mEffectifs <- constituerMatriceEffectifs2(dfSortie$row - 1,
                                              dfSortie$col - 1,
                                              dfSortie[[var]])
      
  dfSortie_mini <- dfToGrid(df = dfCentroids[!duplicated(dfCentroids[,c("x","y")]),],
           sEPSG = "2154",iCellSize = iCellSize)
  effectifs <- as.vector(t(mEffectifs)) #transpose quand on remplit par ligne puis colonne
  dfSortie_mini[[var]] <- effectifs[which(effectifs!=0)]
  dfSortie_mini <- dfSortie_mini[, !names(dfSortie_mini) %in% c("x","y")]
  return(dfSortie_mini) 
  
}

cellsize = 20000L
donnees_carroyees <- cbind(carroyage(dfObservations,xOffset=0,yOffset=0, iCellSize=cellsize,var="SP95"),
      sf::st_drop_geometry(carroyage(dfObservations,xOffset=0,yOffset=0, iCellSize=cellsize,var="nbObs"))
)
donnees_carroyees$prix95 <- donnees_carroyees$SP95 / donnees_carroyees$nbObs

library(cartography)
choroLayer(donnees_carroyees,
, var = "prix95"
, nclass = 5
, method = "fisher-jenks"
, border = NA
, legend.title.txt = "prix du SP95 en centimes\n(non liss)")

  
# Faire des grappes (expliquer ce que c'est... srement en lien avec le krigeage. Reprsenter ce que a veut dire aussi sur une carte)
mGrappes <- constituerGrappes(1, mEffectifs)
mGrappes

# Appliquer l'ensemble du krigeage (reprend une partie des fonctions ci-dessus)
for(bw in c(15000,50000,100000)){
  dfSmoothed <- kernelSmoothing(dfObservations =dfObservations,
                                sEPSG = "2154", iCellSize = cellsize,
                                iBandwidth = bw)
  dfSmoothed$prix95 <- dfSmoothed$SP95 / dfSmoothed$nbObs
  library(cartography)
  choroLayer(dfSmoothed
             , var = "prix95"
             , nclass = 5
             , method = "fisher-jenks"
             , border = NA
             , legend.title.txt = paste0("prix du SP95 en centimes\n(liss avec bw=",bw,")"))
  
}


#### TODO faire des tests avec plusieurs bornes possibles, comme l'exemple qui est fait sur la doc pour la runion. 
```

## TODO 2

- Penser  reprendre aussi des exemples issus du module `btb` de la formation Analyse Urbaine et les intgrer au fil de la vignette
- Supprimer le suggest cartography et adopter les exemples en mapsf
- changer le format des donnes en export pour inciter les utilisateurs  exporter en gpkg et non en shapefiles.

## References :

- https://inseefrlab.github.io/formation-r-lissage-spatial/tuto.html

## Quelques exemples d'utilisation de `btb`

- https://mobile.twitter.com/DavidZumbach/status/1373166163497213952
- http://r.iresmi.net/2019/05/11/kernel-spatial-smoothing-transforming-points-pattern-to-continuous-coverage/
- https://semba-blog.netlify.app/06/30/2020/kernel-smoothin-of-spatial-data/
- https://mobile.twitter.com/raffverduzco/status/1128075094524350464?lang=bg
- https://githubmemory.com/repo/SNStatComp/awesome-official-statistics-software
